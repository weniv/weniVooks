---
chapter: 데이터 구조
title: DataFrame(데이터프레임) 심화
date: 2024-12-11
---

# 1. 데이터 결합 및 분해

## 1.1 데이터 결합

### 1.1.1 equals

`equals` 메서드는 데이터프레임이 다른 데이터프레임과 같은지 비교할 수 있습니다. 출력 결과를 보시면 df1과 df2는 다른 데이터프레임인 것을 확인하실 수 있습니다.

```python
df1 = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
df2 = pl.DataFrame(
    {
        "foo": [3, 2, 1],
        "bar": [8.0, 7.0, 6.0],
        "ham": ["c", "b", "a"],
    }
)

# 데이터프레임1.equals(데이터프레임2)
print(df1.equals(df1))
print(df1.equals(df2))
```

```
True
False
```

df1과 구조, 값 모두 같은 데이터프레임을 생성해보고 비교해보도록 하겠습니다. 출력 결과를 보시면 df와 df1은 같은 데이터프레임을 알 수 있습니다. 이처럼 데이터프레임의 컬럼명과, 구조, 데이터 값들이 모두 같으면 True라고 출력됩니다.

```python
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
print(df.equals(df1))
```

```
True
```

`null_equal=True`(기본값)으로 설정하면 데이터프레임에 널 값이 있는 경우 동등한 데이터프레임 값으로 인식합니다.

```python
df1 = pl.DataFrame(
    {
        "foo": [1, 2, None],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)

print(df1.equals(df1, null_equal=True))
print(df1.equals(df1, null_equal=False))
```

```
True
False
```

이번에는 특정 컬럼의 값이 동일한지 확인해보도록 하겠습니다. 출력 결과를 보시면 df1의 bar 컬럼의 값과 df2의 bar 컬럼의 값은 동일하기 때문에 True로 출력된 것을 보실 수 있습니다.

```python
df2 = pl.DataFrame(
    {
        "foo": [3, 2, 1],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["c", "b", "a"],
    }
)

print(df1['bar'].equals(df2['bar']))
```

```
True
```

### 1.1.2 hstack

`hstack` 메서드는 여러 개의 Series를 수평으로 쌓아 확장된 새로운 데이터프레임을 반환합니다. 이때, `in_place=True`로 설정하시면 바로 원본에 반영됩니다. 출력 결과를 보시면 오른쪽에 apple 열이 추가된 것을 보실 수 있습니다.

```python
x = pl.Series("apple", [10, 20, 30])
print(df1.hstack([x]))
```

```
shape: (3, 4)
┌─────┬─────┬─────┬───────┐
│ foo ┆ bar ┆ ham ┆ apple │
│ --- ┆ --- ┆ --- ┆ ---   │
│ i64 ┆ f64 ┆ str ┆ i64   │
╞═════╪═════╪═════╪═══════╡
│ 1   ┆ 6.0 ┆ a   ┆ 10    │
│ 2   ┆ 7.0 ┆ b   ┆ 20    │
│ 3   ┆ 8.0 ┆ c   ┆ 30    │
└─────┴─────┴─────┴───────┘
```

### 1.1.3 vstack

`vstack` 메서드는 데이터프레임에 데이터를 수직으로 쌓아서 데이터프레임을 늘립니다. 이때, `in_place=True`로 설정하시면 바로 원본에 반영됩니다. 출력 결과를 보시면 아래쪽으로 행의 값이 추가된 것을 보실 수 있습니다.

```python
df2 = pl.DataFrame(
    {
        "foo": [3, 4],
        "bar": [8.0, 9.0],
        "ham": ["c", "d"],
    }
)
print(df1.vstack(df2))
```

```
shape: (5, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6.0 ┆ a   │
│ 2   ┆ 7.0 ┆ b   │
│ 3   ┆ 8.0 ┆ c   │
│ 3   ┆ 8.0 ┆ c   │
│ 4   ┆ 9.0 ┆ d   │
└─────┴─────┴─────┘
```

### 1.1.4 extend

`extend` 메서드는 vstack과 같이 데이터프레임이 지원하는 메모리를 다른 데이터프레임의 값으로 세로로 확장합니다.

```python
df1 = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
df2 = pl.DataFrame({"foo": [10, 20, 30], "bar": [40, 50, 60]})
print(df1.extend(df2))
```

```python
shape: (6, 2)
┌─────┬─────┐
│ foo ┆ bar │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 4   │
│ 2   ┆ 5   │
│ 3   ┆ 6   │
│ 10  ┆ 40  │
│ 20  ┆ 50  │
│ 30  ┆ 60  │
└─────┴─────┘
```

:::div{.callout}
`extend` 메서드는 다른 데이터프레임의 청크를 기존 데이터프레임의 청크에 추가하는 `vstack`과 달리, `extend`는 다른 데이터프레임의 데이터를 기본 메모리 위치에 추가하므로 재할당이 발생할 수 있습니다. 재할당이 발생하지 않으면 결과 데이터프레임 구조에 추가 청크가 없으므로 쿼리가 더 빨라집니다.

- 한 번 추가한 후 쿼리를 수행하려는 경우 `vstack`보다 `extend` 메서드 사용하시는 것을 권장드립니다.
- n개의 행을 추가하고 쿼리를 다시 실행하려는 경우나 쿼리를 수행하기 전에 여러 번 추가하려는 경우 `extend`보다 `vstack`을 추천드립니다.
- 여러 파일을 읽어서 단일 데이터프레임에 저장하려는 경우, 리청크를 통해 `vstack` 메서드를 사용하시길 권장드립니다.

:::

### 1.1.5 update

`update` 메서드는 두 데이터프레임에 같은 컬럼명이 있는 경우 해당 열의 데이터프레임의 값을 다른 데이터프레임의 값으로 업데이트합니다.

df의 B열을 new_df의 B열로 업데이트합니다. 만약, 값이 없거나 null 값인 경우 df 값을 유지합니다.

```python
df = pl.DataFrame(
    {
        "A": [1, 2, 3, 4],
        "B": [400, 500, 600, 700],
    }
)

new_df = pl.DataFrame(
    {
        "B": [-66, None, -99],
        "C": [5, 3, 1],
    }
)

# df.update(새로운데이터프레임)
print(df.update(new_df))
```

```
shape: (4, 2)
┌─────┬─────┐
│ A   ┆ B   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ -66 │
│ 2   ┆ 500 │
│ 3   ┆ -99 │
│ 4   ┆ 700 │
└─────┴─────┘
```

`how` 매개변수는 어떤 방식으로 데이터프레임을 업데이트할 지 조인 방식을 지정합니다. inner 조인을 해보도록 하겠습니다. 출력 결과를 보시면 new_df 행이 3개밖에 없기 때문에 3개의 행만 출력됩니다.

```python
# df.update(new_df, how="조인 종류")
print(df.update(new_df, how="inner"))
```

```
shape: (3, 2)
┌─────┬─────┐
│ A   ┆ B   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ -66 │
│ 2   ┆ 500 │
│ 3   ┆ -99 │
└─────┴─────┘
```

- left : 왼쪽 테이블의 모든 행을 유지하며, 오른쪽 테이블의 매칭되는 값만 업데이트하고 나머지는 원래 값을 유지합니다. 만약, 여러번 매칭되면 행이 중복될 수 있습니다.
- inner : 두 데이터프레임에서 공통으로 존재하는 값, null이 아닌 매칭되는 값만 결과에 포함됩니다.
- full : 왼쪽 테이블의 모든 행을 유지하며, 오른쪽 테이블의 매칭되는 값만 업데이트하고 새로운 데이터가 있는 경우 행에 추가합니다.

이번에는 각 데이터프레임에서 명시적으로 조인할 열을 설정하여 값을 업데이트합니다. B의 열을 기준으로 full join을 해보도록 하겠습니다.

```python
# df.update(새로운데이터프레임, on=["컬럼명"], how="조인 종류")
print(df.update(new_df, on=["B"], how="full"))
```

- on : 조인할 컬럼명, 두 데이터프레임에 해당 컬럼명이 존재해야 합니다. 없음(기본값)으로 설정하면 각 데이터프레임의 암묵적인 행 인덱스가 조인 키로 사용됩니다.

```
shape: (7, 2)
┌──────┬──────┐
│ A    ┆ B    │
│ ---  ┆ ---  │
│ i64  ┆ i64  │
╞══════╪══════╡
│ 1    ┆ 400  │
│ 2    ┆ 500  │
│ 3    ┆ 600  │
│ 4    ┆ 700  │
│ null ┆ null │
│ null ┆ -66  │
│ null ┆ -99  │
└──────┴──────┘
```

왼쪽 데이터프레임의 A 열의 값과 오른쪽 데이터프레임의 C 열의 값이 같은 행을 찾아 해당 행의 B 값을 업데이트해보도록 하겠습니다.

```python
# df.update(새로운데이터프레임, left_on=["기존 데이터프레임 컬럼명"], right_on=["새로운 데이터프레임 컬럼명"], how="조인 종류")
print(df.update(new_df, left_on=["A"], right_on=["C"], how="full"))
```

- left_on : 왼쪽 데이터프레임의 열을 기준으로 조인합니다.
- right_on : 오른쪽 데이터프레임의 열을 기준으로 조인합니다.

```
shape: (5, 2)
┌─────┬─────┐
│ A   ┆ B   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ -99 │
│ 2   ┆ 500 │
│ 3   ┆ 600 │
│ 4   ┆ 700 │
│ 5   ┆ -66 │
└─────┴─────┘
```

`include_nulls` 매개변수는 left/inner 조인을 위한 매개변수로 True로 설정하면 null 값을 포함하여 값 업데이트합니다. 이때, 왼쪽 데이터프레임의 값을 오른쪽 데이터프레임의 null 값으로 덮어씁니다. False(기본값)로 설정하면 오른쪽 데이터프레임의 null 값은 무시됩니다.

```python
print(df.update(new_df, left_on="A", right_on="C", how="full", include_nulls=True))
```

```
shape: (5, 2)
┌─────┬──────┐
│ A   ┆ B    │
│ --- ┆ ---  │
│ i64 ┆ i64  │
╞═════╪══════╡
│ 1   ┆ -99  │
│ 2   ┆ 500  │
│ 3   ┆ null │
│ 4   ┆ 700  │
│ 5   ┆ -66  │
└─────┴──────┘
```

### 1.1.6 join

`join` 메서드는 두 데이터프레임을 특정 컬럼 기준으로 조인합니다. df와 other_df를 ham 열을 기준으로 조인해보도록 하겠습니다. 출력 결과를 보시면 ham의 열에서 공통으로 존재하는 값의 행만 출력된 것을 보실 수 있습니다.

```python
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
other_df = pl.DataFrame(
    {
        "apple": ["x", "y", "z"],
        "ham": ["a", "b", "d"],
    }
)

# df.join(새로운 데이터프레임, on="컬럼명")
print(df.join(other_df, on="ham"))
```

```
shape: (2, 4)
┌─────┬─────┬─────┬───────┐
│ foo ┆ bar ┆ ham ┆ apple │
│ --- ┆ --- ┆ --- ┆ ---   │
│ i64 ┆ f64 ┆ str ┆ str   │
╞═════╪═════╪═════╪═══════╡
│ 1   ┆ 6.0 ┆ a   ┆ x     │
│ 2   ┆ 7.0 ┆ b   ┆ y     │
└─────┴─────┴─────┴───────┘
```

만약, 조인할 열의 이름이 다를 경우 on이 아닌 left_on, right_on을 사용하셔야 합니다. df2와 other_df2를 조인할 때, df의 ham1 열과 other_df2의 ham2 열을 기준으로 조인해보도록 하겠습니다.

```python
df2 = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham1": ["a", "b", "c"],
    }
)
other_df2 = pl.DataFrame(
    {
        "apple": ["x", "y", "z"],
        "ham2": ["a", "b", "d"],
    }
)

# df.join(새로운 데이터프레임, left_on="왼쪽 데이터프레임의 컬럼명", right_on="오른쪽 데이터프레임의 컬럼명")
print(df2.join(other_df2, left_on="ham1", right_on="ham2"))
```

```
shape: (2, 4)
┌─────┬─────┬──────┬───────┐
│ foo ┆ bar ┆ ham1 ┆ apple │
│ --- ┆ --- ┆ ---  ┆ ---   │
│ i64 ┆ f64 ┆ str  ┆ str   │
╞═════╪═════╪══════╪═══════╡
│ 1   ┆ 6.0 ┆ a    ┆ x     │
│ 2   ┆ 7.0 ┆ b    ┆ y     │
└─────┴─────┴──────┴───────┘
```

두 데이터프레임을 어떻게 조인할지 조인 방법을 정할 수 있습니다. df와 other_df를 full join해보도록 하겠습니다.

```python
# df.join(other_df, on="컬럼명", how="조인방법")
print(df.join(other_df, on="ham", how="full"))
```

- inner : 두 데이터프레임에 공통적으로 일치하는 값이 있는 행을 반환합니다.
- left : 왼쪽 데이터프레임의 모든 행과 오른쪽 데이터프레임의 일치하는 행을 반환합니다. 출력 결과는 왼쪽 데이터프레임의 행 순서를 유지합니다.
- full : 왼쪽 또는 오른쪽 데이터프레임에 일치하는 항목이 있을 때 모든 행을 반환합니다.
- semi : 왼쪽 데이터프레임에서 오른쪽 데이터프레임에 일치하는 행이 있는 행을 반환합니다.
- anti : 왼쪽 데이터프레임에서 오른쪽 데이터프레임에 일치하는 항목이 없는 행을 반환합니다.
- cross : 두 데이터프레임의 행의 데카르트 곱을 반환합니다. 이때, on 매개변수는 사용하지 않습니다.

```python
shape: (4, 5)
┌──────┬──────┬──────┬───────┬───────────┐
│ foo  ┆ bar  ┆ ham  ┆ apple ┆ ham_right │
│ ---  ┆ ---  ┆ ---  ┆ ---   ┆ ---       │
│ i64  ┆ f64  ┆ str  ┆ str   ┆ str       │
╞══════╪══════╪══════╪═══════╪═══════════╡
│ 1    ┆ 6.0  ┆ a    ┆ x     ┆ a         │
│ 2    ┆ 7.0  ┆ b    ┆ y     ┆ b         │
│ null ┆ null ┆ null ┆ z     ┆ d         │
│ 3    ┆ 8.0  ┆ c    ┆ null  ┆ null      │
└──────┴──────┴──────┴───────┴───────────┘
```

```python
print(df.join(other_df, on="ham", how="semi"))
```

```
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6.0 ┆ a   │
│ 2   ┆ 7.0 ┆ b   │
└─────┴─────┴─────┘
```

```python
print(df.join(other_df, on="ham", how="anti"))
```

```
shape: (1, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 3   ┆ 8.0 ┆ c   │
└─────┴─────┴─────┘
```

full, cross 조인 결과를 보면 컬럼명\_right 라고 새로운 컬럼이 만들어진 것을 볼 수 있습니다. 만약, 컬럼명\_right가 아닌 다른 접미사를 추가하고 싶다면 `suffix`를 이용하시면 됩니다. 출력 결과를 보시면 접미사가 변경된 것을 보실 수 있습니다.

```python
print(df.join(other_df, on="ham", how="full", suffix="_new"))
```

```python
shape: (4, 5)
┌──────┬──────┬──────┬───────┬─────────┐
│ foo  ┆ bar  ┆ ham  ┆ apple ┆ ham_new │
│ ---  ┆ ---  ┆ ---  ┆ ---   ┆ ---     │
│ i64  ┆ f64  ┆ str  ┆ str   ┆ str     │
╞══════╪══════╪══════╪═══════╪═════════╡
│ 1    ┆ 6.0  ┆ a    ┆ x     ┆ a       │
│ 2    ┆ 7.0  ┆ b    ┆ y     ┆ b       │
│ null ┆ null ┆ null ┆ z     ┆ d       │
│ 3    ┆ 8.0  ┆ c    ┆ null  ┆ null    │
└──────┴──────┴──────┴───────┴─────────┘
```

`coalesce=True`로 설정하여 조인 열을 병합합니다. 만약, 계산식에 의해 조인한다면 병합이 해제됩니다. False(기본값, None)로 설정할 경우 조인 열을 병합하지 않습니다. 출력 결과를 보시면 df의 ham 열과 other_df의 ham 열이 병합된 것을 보실 수 있습니다.

```python
print(df.join(other_df, on="ham", how="left", coalesce=True))
```

```python
shape: (3, 4)
┌─────┬─────┬─────┬───────┐
│ foo ┆ bar ┆ ham ┆ apple │
│ --- ┆ --- ┆ --- ┆ ---   │
│ i64 ┆ f64 ┆ str ┆ str   │
╞═════╪═════╪═════╪═══════╡
│ 1   ┆ 6.0 ┆ a   ┆ x     │
│ 2   ┆ 7.0 ┆ b   ┆ y     │
│ 3   ┆ 8.0 ┆ c   ┆ null  │
└─────┴─────┴─────┴───────┘
```

:::div{.callout}
범주형 데이터가 있는 열에 대한 조인은 `polars.StringCache`를 사용하시길 바랍니다.

```python
# 두 데이터프레임에 범주형 데이터가 있는 경우
df1 = pl.DataFrame({
    "id": [1, 2, 3],
    "category": ["A", "B", "A"]  # 범주형 데이터
})

df2 = pl.DataFrame({
    "id": [1, 2, 4],
    "category": ["A", "C", "B"]  # 범주형 데이터
})

# 범주형 데이터를 StringCache를 사용하여 변환
with pl.StringCache():
    # 각 데이터프레임의 category 열을 범주형으로 변환
    df1 = df1.with_columns(pl.col("category").cast(pl.Categorical))
    df2 = df2.with_columns(pl.col("category").cast(pl.Categorical))

    result = df1.join(df2, on="category", how="left")
    print(result)
```

1. 메모리 효율성: 문자열을 정수로 인코딩하여 메모리 사용을 줄임
2. 성능 향상: 문자열 비교 대신 정수 비교를 수행하여 조인 성능 향상
3. 일관성 유지: 서로 다른 데이터프레임 간에 범주형 데이터의 매핑을 일관되게 유지

특히 대용량 데이터에서 범주형 열을 기준으로 조인할 때 `StringCache`를 사용하면 성능이 크게 향상될 수 있습니다.

:::

`join_nulls=True`로 설정하여 null 값끼리 조인을 허용합니다. False(기본값)은 null 값끼리 조인을 수행하지 않습니다.

```python
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", None, "c"],
    }
)
other_df = pl.DataFrame(
    {
        "apple": ["x", "y", "z"],
        "ham": ["a", None, "d"],
    }
)

print(df.join(other_df, on="ham", how="full", join_nulls=True))
```

```python
shape: (4, 5)
┌──────┬──────┬──────┬───────┬───────────┐
│ foo  ┆ bar  ┆ ham  ┆ apple ┆ ham_right │
│ ---  ┆ ---  ┆ ---  ┆ ---   ┆ ---       │
│ i64  ┆ f64  ┆ str  ┆ str   ┆ str       │
╞══════╪══════╪══════╪═══════╪═══════════╡
│ 1    ┆ 6.0  ┆ a    ┆ x     ┆ a         │
│ 2    ┆ 7.0  ┆ null ┆ y     ┆ null      │
│ null ┆ null ┆ null ┆ z     ┆ d         │
│ 3    ┆ 8.0  ┆ c    ┆ null  ┆ null      │
└──────┴──────┴──────┴───────┴───────────┘
```

```python
# print(df.join(other_df, on="ham", how="full"))
print(df.join(other_df, on="ham", how="full", join_nulls=False))
```

```python
shape: (5, 5)
┌──────┬──────┬──────┬───────┬───────────┐
│ foo  ┆ bar  ┆ ham  ┆ apple ┆ ham_right │
│ ---  ┆ ---  ┆ ---  ┆ ---   ┆ ---       │
│ i64  ┆ f64  ┆ str  ┆ str   ┆ str       │
╞══════╪══════╪══════╪═══════╪═══════════╡
│ 1    ┆ 6.0  ┆ a    ┆ x     ┆ a         │
│ null ┆ null ┆ null ┆ y     ┆ null      │
│ null ┆ null ┆ null ┆ z     ┆ d         │
│ 3    ┆ 8.0  ┆ c    ┆ null  ┆ null      │
│ 2    ┆ 7.0  ┆ null ┆ null  ┆ null      │
└──────┴──────┴──────┴───────┴───────────┘
```

`validate`는 두 데이터프레임 관계가 조인 유형과 동일한지 확인합니다. 만약, 다른 경우 에러가 나게 됩니다.

```python
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "a" , "c"],
    }
)
other_df = pl.DataFrame(
    {
        "apple": ["x", "y", "z"],
        "ham": ["a", "a", "d"],
    }
)

print(df.join(other_df, on="ham", how="full", validate="m:m"))
# print(df.join(other_df, on="ham", how="full", validate="1:m"))
# print(df.join(other_df, on="ham", how="full", validate="m:1"))
# print(df.join(other_df, on="ham", how="full", validate="1:1"))
```

```
shape: (6, 5)
┌──────┬──────┬──────┬───────┬───────────┐
│ foo  ┆ bar  ┆ ham  ┆ apple ┆ ham_right │
│ ---  ┆ ---  ┆ ---  ┆ ---   ┆ ---       │
│ i64  ┆ f64  ┆ str  ┆ str   ┆ str       │
╞══════╪══════╪══════╪═══════╪═══════════╡
│ 1    ┆ 6.0  ┆ a    ┆ x     ┆ a         │
│ 2    ┆ 7.0  ┆ a    ┆ x     ┆ a         │
│ 1    ┆ 6.0  ┆ a    ┆ y     ┆ a         │
│ 2    ┆ 7.0  ┆ a    ┆ y     ┆ a         │
│ null ┆ null ┆ null ┆ z     ┆ d         │
│ 3    ┆ 8.0  ┆ c    ┆ null  ┆ null      │
└──────┴──────┴──────┴───────┴───────────┘
ComputeError: the join keys did not fulfil 1:m validation
ComputeError: the join keys did not fulfil m:1 validation
ComputeError: the join keys did not fulfil 1:1 validation
```

- m:m(many_to_many) : 기본값, 다대다 관계인지 확인합니다. 양쪽 데이터프레임 조인 키가 고유하지 않습니다.
  left_df
  | join_columns | n |
  | ------------ | --- |
  | a | 1 |
  | a | 3 |
  | c | 2 |
  right_df
  | join_columns | n |
  | ------------ | --- |
  | a | 1 |
  | a | 2 |
  | e | 3 |
- 1:m(one_to_many) : 왼쪽 데이터 셋에서 조인 키가 고유한지 확인합니다.
  left_df
  | join_columns | n |
  | ------------ | --- |
  | a | 1 |
  | b | 3 |
  | c | 2 |
  right_df
  | join_columns | n |
  | ------------ | --- |
  | a | 1 |
  | a | 2 |
  | e | 3 |
- m:1(many_to_one) : 오른쪽 데이터 셋에서 조인 키가 고유한지 확인합니다.
  left_df
  | join_columns | n |
  | ------------ | --- |
  | a | 1 |
  | a | 3 |
  | c | 2 |
  right_df
  | join_columns | n |
  | ------------ | --- |
  | a | 1 |
  | d | 2 |
  | e | 3 |
- 1:1(one_to_one) : 왼쪽 및 오른쪽 데이터 셋 모두에서 조인 키가 고유한지 확인합니다.
  left_df
  | join_columns | n |
  | ------------ | --- |
  | a | 1 |
  | b | 3 |
  | c | 2 |
  right_df
  | join_columns | n |
  | ------------ | --- |
  | a | 1 |
  | d | 2 |
  | e | 3 |

### 1.1.7 join_asof

ASOF(As-Of) 조인은 두 테이블을 병합하는 방법 중 하나로, 특히 시계열 데이터에서 유용합니다. ASOF 조인은 기준 열에서 값이 정확히 일치하지 않더라도 가장 가까운 이전 값과 매칭되는 조인 키를 찾습니다. 이는 시계열 데이터의 비동기적 특성을 처리하는데 유용합니다.

동일한 조인 키가 아닌 가장 가까운 조인 키를 기준으로 매칭한다는 점을 제외하면 기존 조인 방법과 비슷합니다. 이때, 두 데이터프레임 모두 조인 키를 기준으로 정렬되어야 합니다.

```python
from datetime import date

gdp = pl.DataFrame(
    {
        "date": pl.date_range(
            date(2016, 1, 1),
            date(2020, 1, 1),
            "1y",
            eager=True,
        ),
        "gdp": [4164, 4411, 4566, 4696, 4827],
    }
)

population = pl.DataFrame(
    {
        "date": [date(2016, 3, 1), date(2018, 8, 1), date(2019, 1, 1)],
        "population": [82.19, 82.66, 83.12],
    }
).sort("date")
```

- date_range(시작날짜, 종료날짜, 간격, eager) : 시작 날짜부터 종료 날짜까지 일정한 간격으로 날짜 시퀀스를 생성합니다.
  - `eager=True`: 결과를 즉시 계산하여 메모리에 저장

```python
# df.join_asof(df2, on="컬럼명", strategy="조인 방법")
print(population.join_asof(gdp, on="date", strategy="backward"))
```

- on: 두 데이터프레임의 조인할 컬럼명입니다. 만약, 두 데이터프레임의 조인할 컬럼명이 다를 경우 join에서와 같이 on 대신 left_on, right_on을 사용하여 각각의 조인할 컬럼명을 입력합니다.
- strategy: 어떤 방법으로 조인할지 설정합니다.
  - backward(기본값) : 각 행에 대해 오른쪽 데이터프레임의 행의 값이 왼쪽 데이터프레임의 행의 값보다 작거나 같은 마지막 행을 선택합니다.
  - forward : 각 행에 대해 오른쪽 데이터프레임의 행의 값이 왼쪽 데이터프레임의 행의 값보다 크거나 같은 첫 번째 행을 선택합니다.
  - nearest : 각 행에 대해 오른쪽 데이터프레임의 행의 값이 왼쪽 데이터프레임의 행의 값에 가장 가까운 값을 가진 마지막 행을 선택합니다. nearest에는 데이터 타입이 문자열인 경우 ASOF 조인이 지원되지 않습니다.

출력 결과를 확인해보시면 날짜가 정확히 일치하지 않는 population의 각 날짜는 gdp에서 가장 가까운 이전 날짜와 매칭된 것을 볼 수 있습니다.

```
shape: (3, 3)
┌────────────┬────────────┬──────┐
│ date       ┆ population ┆ gdp  │
│ ---        ┆ ---        ┆ ---  │
│ date       ┆ f64        ┆ i64  │
╞════════════╪════════════╪══════╡
│ 2016-03-01 ┆ 82.19      ┆ 4164 │
│ 2018-08-01 ┆ 82.66      ┆ 4566 │
│ 2019-01-01 ┆ 83.12      ┆ 4696 │
└────────────┴────────────┴──────┘
```

`strategy=’forward’`로 설정하면, population의 2016-03-01 날짜는 gdp의 2016-01-01과 매칭되고, population의 2018-08-01 날짜는 gdp의 2018-01-01과 매칭됩니다. 이처럼 정확히 일치하지 않는 population의 각 날짜는 gdp에서 가장 가까운 이후의 날짜와 매칭됩니다.

```python
print(population.join_asof(gdp, on="date", strategy="forward"))
```

```
shape: (3, 3)
┌────────────┬────────────┬──────┐
│ date       ┆ population ┆ gdp  │
│ ---        ┆ ---        ┆ ---  │
│ date       ┆ f64        ┆ i64  │
╞════════════╪════════════╪══════╡
│ 2016-03-01 ┆ 82.19      ┆ 4411 │
│ 2018-08-01 ┆ 82.66      ┆ 4696 │
│ 2019-01-01 ┆ 83.12      ┆ 4696 │
└────────────┴────────────┴──────┘
```

`strategy=’nearest’`로 설정하면, population의 2016-03-01 날짜는 gdp의 2017-01-01과 매칭되고, population의 2018-08-01 날짜는 gdp의 2019-01-01과 매칭됩니다. 이처럼 정확히 일치하지 않는 population의 각 날짜가 이전이든 이후든 상관없이 gdp에서 가장 가까운 날짜와 매칭되므로 위의 두 결과를 혼합하여 제공합니다.

```python
print(population.join_asof(gdp, on="date", strategy="nearest"))
```

```
shape: (3, 3)
┌────────────┬────────────┬──────┐
│ date       ┆ population ┆ gdp  │
│ ---        ┆ ---        ┆ ---  │
│ date       ┆ f64        ┆ i64  │
╞════════════╪════════════╪══════╡
│ 2016-03-01 ┆ 82.19      ┆ 4164 │
│ 2018-08-01 ┆ 82.66      ┆ 4696 │
│ 2019-01-01 ┆ 83.12      ┆ 4696 │
└────────────┴────────────┴──────┘
```

`by` 매개변수를 사용하면 asof 조인 전에 다른 열에 먼저 조인할 수 있습니다. 국가별로 먼저 조인한 다음 날짜별로 asof 조인합니다.

```python
gdp_dates = pl.date_range(  # fmt: skip
    date(2016, 1, 1), date(2020, 1, 1), "1y", eager=True
)

gdp2 = pl.DataFrame(
    {
        "country": ["Germany"] * 5 + ["Netherlands"] * 5,
        "date": pl.concat([gdp_dates, gdp_dates]),
        "gdp": [4164, 4411, 4566, 4696, 4827, 784, 833, 914, 910, 909],
    }
).sort("country", "date")

pop2 = pl.DataFrame(
    {
        "country": ["Germany"] * 3 + ["Netherlands"] * 3,
        "date": [
            date(2016, 3, 1),
            date(2018, 8, 1),
            date(2019, 1, 1),
            date(2016, 3, 1),
            date(2018, 8, 1),
            date(2019, 1, 1),
        ],
        "population": [82.19, 82.66, 83.12, 17.11, 17.32, 17.40],
    }
).sort("country", "date")

# df.join_asof(df2, by="첫번째 조인 컬럼명", on="두번째 조인 컬럼명", strategy="조인방법")
print(pop2.join_asof(gdp2, by="country", on="date", strategy="nearest"))
```

출력 결과를 보시면 population의 국가가 Germany 2016-03-01, 날짜는 gdp의 국가가 Germany 2016-01-01과 매칭되고, population의 국가가 Germany 2018-08-01 날짜는 gdp의 국가가 Germany 2019-01-01과 매칭됩니다.

on 매개변수와 마찬가지로 두 데이터프레임의 컬럼명이 다를 경우 by_left, by_right 매개변수에 각각의 컬럼명을 입력합니다.

```
shape: (6, 4)
┌─────────────┬────────────┬────────────┬──────┐
│ country     ┆ date       ┆ population ┆ gdp  │
│ ---         ┆ ---        ┆ ---        ┆ ---  │
│ str         ┆ date       ┆ f64        ┆ i64  │
╞═════════════╪════════════╪════════════╪══════╡
│ Germany     ┆ 2016-03-01 ┆ 82.19      ┆ 4164 │
│ Germany     ┆ 2018-08-01 ┆ 82.66      ┆ 4696 │
│ Germany     ┆ 2019-01-01 ┆ 83.12      ┆ 4696 │
│ Netherlands ┆ 2016-03-01 ┆ 17.11      ┆ 784  │
│ Netherlands ┆ 2018-08-01 ┆ 17.32      ┆ 910  │
│ Netherlands ┆ 2019-01-01 ┆ 17.4       ┆ 910  │
└─────────────┴────────────┴────────────┴──────┘
```

두 데이터프레임에 컬럼명이 동일한 경우 `suffix` 매개변수에 이름이 중복된 열에 추가할 접미사를 입력하여 출력할 수 있습니다.

```python
#  'value' 열이 있는 경우
df1 = pl.DataFrame({
    "date": [date(2023, 1, 1), date(2023, 2, 1), date(2023, 3, 1)],
    "value": [100, 200, 300]
})

df2 = pl.DataFrame({
    "date": [date(2023, 1, 15), date(2023, 2, 15), date(2023, 3, 15)],
    "value": [150, 250, 350]
})

# suffix를 사용하여 중복 열 이름 처리
result = df1.join_asof(df2, on="date", suffix="_new")
print(result)
```

```
shape: (3, 3)
┌────────────┬───────┬────────────┐
│ date       ┆ value ┆ value_new  │
│ ---        ┆ ---   ┆ ---        │
│ date       ┆ i64   ┆ i64        │
╞════════════╪═══════╪════════════╡
│ 2023-01-01 ┆ 100   ┆ null       │
│ 2023-02-01 ┆ 200   ┆ 150        │
│ 2023-03-01 ┆ 300   ┆ 250        │
└────────────┴───────┴────────────┘
```

- tolerance : 숫자 허용 오차로 값을 설정하여 가까운 조인키가 범위 내에 있는 경우에만 조인이 수행됩니다. 데이터 타입이 "Date", "Datetime", "Duration", "Time"의 열에 대해 asof 조인을 수행하는 경우 datetime.timedelta 개체 또는 아래의 문자열 언어를 사용합니다.

- 1ns(1나노초)
- 1us(1마이크로초)
- 1ms(1밀리초)
- 1s(1초)
- 1m(1분)
- 1h(1시간)

ex) 3d12h4m25s
(3일, 12시간 4분 25초)

- 1d(1역일)
- 1w(1역주)
- 1mo(1역월)
- 1q(1역분기)
- 1y(1역연도)

:::div{.callout}
'역일'이란 다음 날의 해당 시간(서머타임으로 인해 24시간이 아닐 수 있음)을 의미합니다. '역주', '역월', '역분기', '역연도'도 마찬가지입니다.

:::

```python
df1 = pl.DataFrame({
    "date": [date(2023, 1, 1), date(2023, 2, 1), date(2023, 3, 1)],
    "value": [100, 200, 300]
})

df2 = pl.DataFrame({
    "date": [date(2023, 1, 15), date(2023, 2, 15), date(2023, 3, 15)],
    "value": [150, 250, 350]
})

# 20일 이내의 데이터 매칭
print(df1.join_asof(
    df2,
    on="date",
    tolerance="20d",  # 20일로 허용 오차 증가
    suffix="_new"
))
```

```
shape: (3, 3)
┌────────────┬───────┬─────────────┐
│ date       ┆ value ┆ value_new   │
│ ---        ┆ ---   ┆ ---         │
│ date       ┆ i64   ┆ i64         │
╞════════════╪═══════╪═════════════╡
│ 2023-01-01 ┆ 100   ┆ null        │
│ 2023-02-01 ┆ 200   ┆ 150         │
│ 2023-03-01 ┆ 300   ┆ 250         │
└────────────┴───────┴─────────────┘
```

대용량 데이터 셋에서 병렬 처리 활성화하는 방법에 대해 알아보도록 하겠습니다.

```python
from datetime import date

df1 = pl.DataFrame({
    "date": pl.date_range(date(2023, 1, 1), date(2023, 12, 31), "1d", eager=True),  # eager=True 추가
    "value": list(range(365))
})

df2 = pl.DataFrame({
    "date": pl.date_range(date(2023, 1, 15), date(2023, 12, 15), "1d", eager=True),  # eager=True 추가
    "value": list(range(335))
})

# 병렬 처리 허용
result_allow = df1.join_asof(
    df2,
    on="date",
    allow_parallel=True,
    suffix="_new"
)
print(result_allow.head())

# 병렬 처리 강제
result_force = df1.join_asof(
    df2,
    on="date",
    force_parallel=True,
    suffix="_new"
)
print(result_force.head())
```

- allow_parallel : 두 데이터프레임을 조인할 때, 컴퓨터의 여러 코어를 사용해서 동시에(병렬로) 처리할지 여부를 설정합니다. True로 설정하면 병렬 처리를 허용합니다.
- force_parallel : 두 데이터프레임을 조인할 때, 컴퓨터의 여러 코어를 사용해서 동시에(병렬로) 처리하도록 강제합니다. 선택이 아닌 강제로 병렬 처리를 실행합니다.

```
shape: (5, 3)
┌────────────┬───────┬─────────────┐
│ date       ┆ value ┆ value_new   │
│ ---        ┆ ---   ┆ ---         │
│ date       ┆ i64   ┆ i64         │
╞════════════╪═══════╪═════════════╡
│ 2023-01-01 ┆ 0     ┆ null        │
│ 2023-01-02 ┆ 1     ┆ null        │
│ 2023-01-03 ┆ 2     ┆ null        │
│ 2023-01-04 ┆ 3     ┆ null        │
│ 2023-01-05 ┆ 4     ┆ null        │
└────────────┴───────┴─────────────┘
shape: (5, 3)
┌────────────┬───────┬─────────────┐
│ date       ┆ value ┆ value_new   │
│ ---        ┆ ---   ┆ ---         │
│ date       ┆ i64   ┆ i64         │
╞════════════╪═══════╪═════════════╡
│ 2023-01-01 ┆ 0     ┆ null        │
│ 2023-01-02 ┆ 1     ┆ null        │
│ 2023-01-03 ┆ 2     ┆ null        │
│ 2023-01-04 ┆ 3     ┆ null        │
│ 2023-01-05 ┆ 4     ┆ null        │
└────────────┴───────┴─────────────┘
```

```python
df1 = pl.DataFrame({
    "date": [date(2023, 1, 1), date(2023, 2, 1), date(2023, 3, 1)],
    "value": [100, None, 300]
})

df2 = pl.DataFrame({
    "date": [date(2023, 1, 15), date(2023, 2, 15), date(2023, 3, 15)],
    "value": [150, 250, 350]
})

# coalesce를 True로 설정하여 조인 열 병합
result = df1.join_asof(
    df2,
    on="date",
    coalesce=True,# None 값을 df2의 값으로 대체
    suffix="_new"
)
print(result)
```

- coalesce : 조인할 때 같은 이름의 열들을 하나로 병합하는 설정입니다. 단순 열(col)이 아닌 다른 표현식으로 조인하면 이 병합 기능이 해제됩니다.
  - True: 항상 조인 열을 병합합니다.
  - False: 조인 열을 병합하지 않습니다.

```
shape: (3, 3)
┌────────────┬───────┬─────────────┐
│ date       ┆ value ┆ value_new   │
│ ---        ┆ ---   ┆ ---         │
│ date       ┆ i64   ┆ i64         │
╞════════════╪═══════╪═════════════╡
│ 2023-01-01 ┆ 100   ┆ null        │
│ 2023-02-01 ┆ null  ┆ 150         │
│ 2023-03-01 ┆ 300   ┆ 250         │
└────────────┴───────┴─────────────┘
```

### 1.1.8 merge_sorted

`merge_sorted` 메서드는 정렬된 두 개의 데이터프레임을 가져와 정렬된 조인 키로 병합합니다. 출력 결과도 정렬되어 나옵니다.

이때, 두 데이터프레임의 스키마는 동일해야하며, 각가의 데이터 프레임은 정렬할 키를 기준으로 정렬되어 있어야 합니다.

```python
df0 = pl.DataFrame(
    {"name": ["steve", "elise", "bob"], "age": [42, 44, 18]}
).sort("age")

df1 = pl.DataFrame(
    {"name": ["anna", "megan", "steve", "thomas"], "age": [21, 33, 42, 20]}
).sort("age")

# 데이터프레임1.merge_sorted(데이터프레임2, key="정렬할 컬럼명")
print(df0.merge_sorted(df1, key="age"))
```

```
shape: (7, 2)
┌────────┬─────┐
│ name   ┆ age │
│ ---    ┆ --- │
│ str    ┆ i64 │
╞════════╪═════╡
│ bob    ┆ 18  │
│ thomas ┆ 20  │
│ anna   ┆ 21  │
│ megan  ┆ 33  │
│ steve  ┆ 42  │
│ steve  ┆ 42  │
│ elise  ┆ 44  │
└────────┴─────┘
```

## 1.2 데이터 분해

### 1.2.1 explode

explode 메서드는 지정된 열을 분해하여 데이터 프레임을 긴 형식으로 분해합니다. 분해되는 기본 열은 리스트 또는 배열 데이터 타입이어야 합니다.

```python
df = pl.DataFrame({
        "letters": ["a", "a", "b", "c"],
        "numbers": [[1], [2, 3], [4, 5], [6, 7, 8]],
    })
print(df.explode("numbers"))
```

```python
shape: (8, 2)
┌─────────┬─────────┐
│ letters ┆ numbers │
│ ---     ┆ ---     │
│ str     ┆ i64     │
╞═════════╪═════════╡
│ a       ┆ 1       │
│ a       ┆ 2       │
│ a       ┆ 3       │
│ b       ┆ 4       │
│ b       ┆ 5       │
│ c       ┆ 6       │
│ c       ┆ 7       │
│ c       ┆ 8       │
└─────────┴─────────┘
```

### 1.2.2 unnest

unnest 메서드는 각 필드에 대해 구조체 열을 별도의 열로 분해합니다. 새 열은 기존 열의 위치에 있는 데이터프레임에 옆에 추가됩니다.

```python
df = pl.DataFrame({
        "before": ["foo", "bar"],
        "t_a": [1, 2],
        "t_b": ["a", "b"],
        "t_c": [True, None],
        "t_d": [[1, 2], [3]],
        "after": ["baz", "womp"],
    }).select("before", pl.struct(pl.col("^t_.$")).alias("t_struct"), "after")

print(df.unnest("t_struct"))
```

- `pl.struct()`는 이 선택된 열들을 하나의 구조체로 묶습니다.
- `^t_.$` : "t\_"로 시작하고 그 뒤에 한 문자가 오는 모든 열을 선택합니다.

```python
shape: (2, 6)
┌────────┬─────┬─────┬──────┬───────────┬───────┐
│ before ┆ t_a ┆ t_b ┆ t_c  ┆ t_d       ┆ after │
│ ---    ┆ --- ┆ --- ┆ ---  ┆ ---       ┆ ---   │
│ str    ┆ i64 ┆ str ┆ bool ┆ list[i64] ┆ str   │
╞════════╪═════╪═════╪══════╪═══════════╪═══════╡
│ foo    ┆ 1   ┆ a   ┆ true ┆ [1, 2]    ┆ baz   │
│ bar    ┆ 2   ┆ b   ┆ null ┆ [3]       ┆ womp  │
└────────┴─────┴─────┴──────┴───────────┴───────┘
```

# 2. 데이터 그룹화

## 2.1 group_by

그룹별로 집계를 수행합니다. 컬럼명을 기준으로 그룹화하고 agg로 다른 열의 그룹화된 집계를 계산합니다.

```python
df = pl.DataFrame(
    {
        "a": ["a", "b", "a", "b", "c"],
        "b": [1, 2, 1, 3, 3],
        "c": [5, 4, 3, 2, 1],
    }
)

# df.group_by("컬럼명").agg(연산)
print(df.group_by("a").agg(pl.col("b").sum()))
```

```python
shape: (3, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ b   ┆ 5   │
│ a   ┆ 2   │
│ c   ┆ 3   │
└─────┴─────┘
```

위에 코드를 실행한 것을 보면 그룹의 순서가 입력과 일치하지 않는 것을 볼 수 있습니다. 만약, 일치하도록 유지하려면 `maintain_order=True`로 설정합니다. True로 설정하면 스트리밍 엔진에서 실행될 가능성이 차단되며, False로 설정했을 때보다 느립니다. 각 그룹 내에서의 행 순서는 기존 순서와 일치합니다.

```python
print(df.group_by("a", maintain_order=True).agg(pl.col("c")))
```

```python
shape: (3, 2)
┌─────┬───────────┐
│ a   ┆ c         │
│ --- ┆ ---       │
│ str ┆ list[i64] │
╞═════╪═══════════╡
│ a   ┆ [5, 3]    │
│ b   ┆ [4, 2]    │
│ c   ┆ [1]       │
└─────┴───────────┘
```

그룹화할 추가 열을 쉼표(,)나 리스트로 전달하여 여러 열을 기준으로 그룹화 할 수 있습니다. 그룹화 한 컬럼명은 사용된 컬럼명으로 집계에 사용할 수 없습니다.

```python
print(df.group_by(["a", "b"]).agg(pl.max("c")))
```

```python
shape: (4, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ b   ┆ 2   ┆ 4   │
│ b   ┆ 3   ┆ 2   │
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘
```

```python
print(df.group_by("a", pl.col("b") // 2).agg(pl.col("c").mean()))
```

```python
shape: (3, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ f64 │
╞═════╪═════╪═════╡
│ b   ┆ 1   ┆ 3.0 │
│ c   ┆ 1   ┆ 1.0 │
│ a   ┆ 0   ┆ 4.0 │
└─────┴─────┴─────┘
```

group_by 후 반환된 객체는 반복 가능하며 각 그룹의 컬럼명과 데이터를 반환합니다.

```python
for name, data in df.group_by("a"):
    print(name)
    print(data)
```

```python
a
shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ a   ┆ 1   ┆ 3   │
└─────┴─────┴─────┘
b
shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 2   ┆ 4   │
│ b   ┆ 3   ┆ 2   │
└─────┴─────┴─────┘
c
shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘
```

## **2.2 group_by_dynamic**

시간 값(또는 Int32, Int64 유형의 인덱스 값)을 기준으로 그룹화합니다.

every, period, offset 인수로 문자열로 그룹화 할 기간을 설정할 수 있습니다.

- 1ns(1나노초)
- 1us(1마이크로초)
- 1ms(1밀리초)
- 1s(1초)
- 1m(1분)
- 1h(1시간)

ex) 3d12h4m25s
(3일, 12시간 4분 25초)

- 1d(1역일)
- 1w(1역주)
- 1mo(1역월)
- 1q(1역분기)
- 1y(1역연도)
    <aside>
    💡 '역일'이란 다음 날의 해당 시간(서머타임으로 인해 24시간이 아닐 수 있음)을 의미합니다. '역주', '역월', '역분기', '역연도'도 마찬가지입니다.
    
    </aside>

시간이 계산되고 출력 결과에 행이 할당됩니다. group_by과 다른 점은 하나의 행이 여러 그룹의 멤버가 될 수 있다는 점입니다.

- [start, start + period)
- [start + every, start + every + period)
- [start + 2*every, start + 2*every + period)
- …

여기서 start는 start_by, offset, every 매개변수에 따라 가장 빠른 시간으로 결정됩니다.

```python
from datetime import datetime

df = pl.DataFrame(
    {
        "time": pl.datetime_range(
            start=datetime(2021, 12, 16),
            end=datetime(2021, 12, 16, 3),
            interval="30m",
            eager=True,
        ),
        "n": range(7),
    }
)

print(df)
```

```python
shape: (7, 2)
┌─────────────────────┬─────┐
│ time                ┆ n   │
│ ---                 ┆ --- │
│ datetime[μs]        ┆ i64 │
╞═════════════════════╪═════╡
│ 2021-12-16 00:00:00 ┆ 0   │
│ 2021-12-16 00:30:00 ┆ 1   │
│ 2021-12-16 01:00:00 ┆ 2   │
│ 2021-12-16 01:30:00 ┆ 3   │
│ 2021-12-16 02:00:00 ┆ 4   │
│ 2021-12-16 02:30:00 ┆ 5   │
│ 2021-12-16 03:00:00 ┆ 6   │
└─────────────────────┴─────┘
```

2021-12-16 00:00:00부터 1시간 단위로 그룹화합니다.

```python
# df.group_by_dynamic("컬럼명", every="간격", closed="닫을 방향").agg(pl.col("n"))
print(df.group_by_dynamic("time", every="1h", closed="right").agg(pl.col("n")))
```

```python
shape: (4, 2)
┌─────────────────────┬───────────┐
│ time                ┆ n         │
│ ---                 ┆ ---       │
│ datetime[μs]        ┆ list[i64] │
╞═════════════════════╪═══════════╡
│ 2021-12-15 23:00:00 ┆ [0]       │
│ 2021-12-16 00:00:00 ┆ [1, 2]    │
│ 2021-12-16 01:00:00 ┆ [3, 4]    │
│ 2021-12-16 02:00:00 ┆ [5, 6]    │
└─────────────────────┴───────────┘
```

- 컬럼명 : 그룹화에 사용되는 열로 데이터 타입은 보통 날짜/시간 유형입니다. 이때, 그룹화 할 열은 오름차순으로 정렬해야 합니다. 오름차순으로 정렬하지 않을 경우 에러가 납니다.

  ```python
  new_row = pl.DataFrame(
      {
          "time": [datetime(2021, 12, 17, 2, 0, 0),datetime(2021, 12, 18, 2, 0, 0),datetime(2021, 12, 19, 2, 0, 0),datetime(2021, 12, 20, 2, 0, 0)],
          "n": [4,6,3,2]
      }
  )

  new_df = new_row.vstack(df)
  print(new_df)
  ```

  ```python
  shape: (11, 2)
  ┌─────────────────────┬─────┐
  │ time                ┆ n   │
  │ ---                 ┆ --- │
  │ datetime[μs]        ┆ i64 │
  ╞═════════════════════╪═════╡
  │ 2021-12-17 02:00:00 ┆ 4   │
  │ 2021-12-18 02:00:00 ┆ 6   │
  │ 2021-12-19 02:00:00 ┆ 3   │
  │ 2021-12-20 02:00:00 ┆ 2   │
  │ 2021-12-16 00:00:00 ┆ 0   │
  │ …                   ┆ …   │
  │ 2021-12-16 01:00:00 ┆ 2   │
  │ 2021-12-16 01:30:00 ┆ 3   │
  │ 2021-12-16 02:00:00 ┆ 4   │
  │ 2021-12-16 02:30:00 ┆ 5   │
  │ 2021-12-16 03:00:00 ┆ 6   │
  └─────────────────────┴─────┘
  ```

  ```python
  print(new_df.group_by_dynamic("time", every="1h", closed="right").agg(pl.col("n")))
  ```

  ```python
  InvalidOperationError: argument in operation 'group_by_dynamic' is not sorted, please sort the 'expr/series/column' first
  ```

- closed : 시간 간격의 어느 쪽을 닫을지 정의합니다.(포함관계)
  - right :시작 값은 `df[0,'time']`에서 -1시간 된 값이며, 종료 값은 `df[-1,'time']` 입니다. 집계할 때는 시작 경계값 < time ≤ 종료 경계값이 됩니다.
  - left(기본값) : 시작 값은 `df[0,'time']`이며, 종료 값은 `df[-1,'time']`에서 +1시간 된 값 입니다. 집계할 때는 시작 경계값 ≤ time < 종료 경계값이 됩니다.
    ```python
    print(df.group_by_dynamic("time", every="1h", closed="left").agg(pl.col("n")))
    ```
    ```python
    shape: (4, 2)
    ┌─────────────────────┬───────────┐
    │ time                ┆ n         │
    │ ---                 ┆ ---       │
    │ datetime[μs]        ┆ list[i64] │
    ╞═════════════════════╪═══════════╡
    │ 2021-12-16 00:00:00 ┆ [0, 1]    │
    │ 2021-12-16 01:00:00 ┆ [2, 3]    │
    │ 2021-12-16 02:00:00 ┆ [4, 5]    │
    │ 2021-12-16 03:00:00 ┆ [6]       │
    └─────────────────────┴───────────┘
    ```
  - both : 시작 값은 `df[0,'time']`에서 -1시간 된 값이며, 종료 값은 `df[-1,'time']`에서 +1시간 된 값 입니다. 집계할 때는 시작 경계값 ≤ time ≤ 종료 경계값이 됩니다. 이처럼 time 값은 두 경계에 모두 속합니다.
    ```python
    print(df.group_by_dynamic("time", every="1h", closed="both").agg(pl.col("n")))
    ```
    ```python
    shape: (5, 2)
    ┌─────────────────────┬───────────┐
    │ time                ┆ n         │
    │ ---                 ┆ ---       │
    │ datetime[μs]        ┆ list[i64] │
    ╞═════════════════════╪═══════════╡
    │ 2021-12-15 23:00:00 ┆ [0]       │
    │ 2021-12-16 00:00:00 ┆ [0, 1, 2] │
    │ 2021-12-16 01:00:00 ┆ [2, 3, 4] │
    │ 2021-12-16 02:00:00 ┆ [4, 5, 6] │
    │ 2021-12-16 03:00:00 ┆ [6]       │
    └─────────────────────┴───────────┘
    ```
  - none : 시작 값은 `df[0,'time']` 값이며, 종료 값은 `df[-1,'time']` 값 입니다. 집계할 때는 시작 경계값 < time < 종료 경계값 이 됩니다. 이처럼 time 값은 두 경계에 모두 포함하지 않으며, 중간에 값이 있는 경우만 출력합니다.
    ```python
    print(df.group_by_dynamic("time", every="1h", closed="none").agg(pl.col("n")))
    ```
    ```python
    shape: (3, 2)
    ┌─────────────────────┬───────────┐
    │ time                ┆ n         │
    │ ---                 ┆ ---       │
    │ datetime[μs]        ┆ list[i64] │
    ╞═════════════════════╪═══════════╡
    │ 2021-12-16 00:00:00 ┆ [1]       │
    │ 2021-12-16 01:00:00 ┆ [3]       │
    │ 2021-12-16 02:00:00 ┆ [5]       │
    └─────────────────────┴───────────┘
    ```
- offset : 그룹화 할 범위를 넓힐 수 있습니다. 기본값은 0이며, start_by가 'datapoint'인 경우 적용되지 않습니다.
  ```python
  print(df.group_by_dynamic("time", every="1h", include_boundaries=True, offset="10m").agg(pl.col("n")))
  ```
  ```python
  shape: (4, 4)
  ┌─────────────────────┬─────────────────────┬─────────────────────┬───────────┐
  │ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n         │
  │ ---                 ┆ ---                 ┆ ---                 ┆ ---       │
  │ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64] │
  ╞═════════════════════╪═════════════════════╪═════════════════════╪═══════════╡
  │ 2021-12-15 23:10:00 ┆ 2021-12-16 00:10:00 ┆ 2021-12-15 23:10:00 ┆ [0]       │
  │ 2021-12-16 00:10:00 ┆ 2021-12-16 01:10:00 ┆ 2021-12-16 00:10:00 ┆ [1, 2]    │
  │ 2021-12-16 01:10:00 ┆ 2021-12-16 02:10:00 ┆ 2021-12-16 01:10:00 ┆ [3, 4]    │
  │ 2021-12-16 02:10:00 ┆ 2021-12-16 03:10:00 ┆ 2021-12-16 02:10:00 ┆ [5, 6]    │
  └─────────────────────┴─────────────────────┴─────────────────────┴───────────┘
  ```
- label : 출력 결과에 사용할 라벨 정의할 수 있습니다.
  - left : 시작 경계값을 time 값으로 설정합니다.
    ```python
    print(df.group_by_dynamic(
        "time", every="1h", include_boundaries=True, closed="right", label='right'
    ).agg(pl.col("n")))
    ```
    ```python
    shape: (4, 4)
    ┌─────────────────────┬─────────────────────┬─────────────────────┬───────────┐
    │ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n         │
    │ ---                 ┆ ---                 ┆ ---                 ┆ ---       │
    │ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64] │
    ╞═════════════════════╪═════════════════════╪═════════════════════╪═══════════╡
    │ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-15 23:00:00 ┆ [0]       │
    │ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ [1, 2]    │
    │ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ [3, 4]    │
    │ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ [5, 6]    │
    └─────────────────────┴─────────────────────┴─────────────────────┴───────────┘
    ```
  - right : 종료 경계값을 time 값으로 설정합니다.
    ```python
    print(df.group_by_dynamic(
        "time", every="1h", include_boundaries=True, closed="right", label='right'
    ).agg(pl.col("n")))
    ```
    ```python
    shape: (4, 4)
    ┌─────────────────────┬─────────────────────┬─────────────────────┬───────────┐
    │ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n         │
    │ ---                 ┆ ---                 ┆ ---                 ┆ ---       │
    │ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64] │
    ╞═════════════════════╪═════════════════════╪═════════════════════╪═══════════╡
    │ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 00:00:00 ┆ [0]       │
    │ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 01:00:00 ┆ [1, 2]    │
    │ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 02:00:00 ┆ [3, 4]    │
    │ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 03:00:00 ┆ [5, 6]    │
    └─────────────────────┴─────────────────────┴─────────────────────┴───────────┘
    ```
  - datapoint : 주어진 time 리스트에서 첫 번째 값으로 레이블이 경계 중 하나에 위치할 필요가 없는 경우, datapoint를 선택하면 성능을 극대화할 수 있습니다.
    ```python
    print(df.group_by_dynamic(
        "time", every="1h", include_boundaries=True, closed="right", label='datapoint'
    ).agg(pl.col("n")))
    ```
    ```python
    shape: (4, 4)
    ┌─────────────────────┬─────────────────────┬─────────────────────┬───────────┐
    │ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n         │
    │ ---                 ┆ ---                 ┆ ---                 ┆ ---       │
    │ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64] │
    ╞═════════════════════╪═════════════════════╪═════════════════════╪═══════════╡
    │ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 00:00:00 ┆ [0]       │
    │ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:30:00 ┆ [1, 2]    │
    │ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:30:00 ┆ [3, 4]    │
    │ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:30:00 ┆ [5, 6]    │
    └─────────────────────┴─────────────────────┴─────────────────────┴───────────┘
    ```
- `include_boundaries=True`로 설정할 경우 범위의 시작과 종료를 결과에 추가할 수 있습니다. 이렇게 하면 병렬 처리가 더 어려워지므로 성능에 영향을 미칩니다.
  ```python
  print(df.group_by_dynamic(
      "time", every="1h", include_boundaries=True, closed="right"
  ).agg(pl.col("n").mean()))
  ```
  ```python
  shape: (4, 4)
  ┌─────────────────────┬─────────────────────┬─────────────────────┬─────┐
  │ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n   │
  │ ---                 ┆ ---                 ┆ ---                 ┆ --- │
  │ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ f64 │
  ╞═════════════════════╪═════════════════════╪═════════════════════╪═════╡
  │ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-15 23:00:00 ┆ 0.0 │
  │ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ 1.5 │
  │ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ 3.5 │
  │ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ 5.5 │
  └─────────────────────┴─────────────────────┴─────────────────────┴─────┘
  ```
- start_by : 첫 번째 시작 경계값을 결정하는 방법을 설정할 수 있습니다.

  - window(기본값): 가장 빠른 시간을 가져와서 매번 잘라냅니다. 주별은 월요일부터 시작됩니다.
  - datapoint : 처음 발견된 데이터부터 시작합니다.
    ```python
    print(df.group_by_dynamic(
        "time", every="1h", include_boundaries=True, closed="right", start_by='datapoint'
    ).agg(pl.col("n")))
    ```
    ```python
    shape: (3, 4)
    ┌─────────────────────┬─────────────────────┬─────────────────────┬───────────┐
    │ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n         │
    │ ---                 ┆ ---                 ┆ ---                 ┆ ---       │
    │ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64] │
    ╞═════════════════════╪═════════════════════╪═════════════════════╪═══════════╡
    │ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ [1, 2]    │
    │ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ [3, 4]    │
    │ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ [5, 6]    │
    └─────────────────────┴─────────────────────┴─────────────────────┴───────────┘
    ```
  - sunday : 주별로 그룹화 할 때(every에 'w'가 포함된 경우), monday, tuesday, wednesday, thursday, friday, saturday, sunday 값이 인수로 들어갈 수 있습니다.
    만약, sunday를 넣을 경우 시작 경계값의 날짜의 요일이 전주 일요일부터 시작하게 됩니다. 출력 결과는 가장 빠른 시간이 범위 안이나 앞에 있을 때까지 뒤로 이동합니다.

    ````python
    new_row = pl.DataFrame(
    {
    "time": [datetime(2021, 12, 17, 2, 0, 0),datetime(2021, 12, 18, 2, 0, 0),datetime(2021, 12, 19, 2, 0, 0),datetime(2021, 12, 20, 2, 0, 0)],
    "n": [4,6,3,2]
    }
    )

        new_df = df.vstack(new_row)
        print(new_df)
        ```

        ```python
        shape: (11, 2)
        ┌─────────────────────┬─────┐
        │ time                ┆ n   │
        │ ---                 ┆ --- │
        │ datetime[μs]        ┆ i64 │
        ╞═════════════════════╪═════╡
        │ 2021-12-16 00:00:00 ┆ 0   │
        │ 2021-12-16 00:30:00 ┆ 1   │
        │ 2021-12-16 01:00:00 ┆ 2   │
        │ 2021-12-16 01:30:00 ┆ 3   │
        │ 2021-12-16 02:00:00 ┆ 4   │
        │ …                   ┆ …   │
        │ 2021-12-16 03:00:00 ┆ 6   │
        │ 2021-12-17 02:00:00 ┆ 4   │
        │ 2021-12-18 02:00:00 ┆ 6   │
        │ 2021-12-19 02:00:00 ┆ 3   │
        │ 2021-12-20 02:00:00 ┆ 2   │
        └─────────────────────┴─────┘
        ```

        ```python
        print(new_df.group_by_dynamic(
            "time", every="1w", include_boundaries=True, closed="right", start_by='sunday'
        ).agg(pl.col("n")))
        ```

        ```python
        shape: (2, 4)
        ┌─────────────────────┬─────────────────────┬─────────────────────┬─────────────┐
        │ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n           │
        │ ---                 ┆ ---                 ┆ ---                 ┆ ---         │
        │ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64]   │
        ╞═════════════════════╪═════════════════════╪═════════════════════╪═════════════╡
        │ 2021-12-12 00:00:00 ┆ 2021-12-19 00:00:00 ┆ 2021-12-12 00:00:00 ┆ [0, 1, … 6] │
        │ 2021-12-19 00:00:00 ┆ 2021-12-26 00:00:00 ┆ 2021-12-19 00:00:00 ┆ [3, 2]      │
        └─────────────────────┴─────────────────────┴─────────────────────┴─────────────┘
        ```

        ![Untitled](%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%91%E1%85%B3%E1%84%85%E1%85%A6%E1%84%8B%E1%85%B5%E1%86%B7%20%E1%84%89%E1%85%B5%E1%86%B7%E1%84%92%E1%85%AA%20-%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%80%E1%85%B3%E1%84%85%E1%85%AE%E1%86%B8%E1%84%92%E1%85%AA%2015779f9807ba8028aa48e10294d1cf85/Untitled.png)
    ````

다른 컬럼 그룹화와 결합할 수도 있습니다. group_by에 컬럼명을 입력하여 어떤 열을 기준으로 그룹별로 집계할 지 정할 수 있습니다. group_by가 전달되면 출력 결과는 그룹화 할 컬럼을 기준으로 각 그룹 내에서 오름차순으로 정렬됩니다.

```python
df = df.with_columns(groups=pl.Series(["a", "a", "a", "b", "b", "a", "a"]))
print(df)
```

```python
shape: (7, 3)
┌─────────────────────┬─────┬────────┐
│ time                ┆ n   ┆ groups │
│ ---                 ┆ --- ┆ ---    │
│ datetime[μs]        ┆ i64 ┆ str    │
╞═════════════════════╪═════╪════════╡
│ 2021-12-16 00:00:00 ┆ 0   ┆ a      │
│ 2021-12-16 00:30:00 ┆ 1   ┆ a      │
│ 2021-12-16 01:00:00 ┆ 2   ┆ a      │
│ 2021-12-16 01:30:00 ┆ 3   ┆ b      │
│ 2021-12-16 02:00:00 ┆ 4   ┆ b      │
│ 2021-12-16 02:30:00 ┆ 5   ┆ a      │
│ 2021-12-16 03:00:00 ┆ 6   ┆ a      │
└─────────────────────┴─────┴────────┘
```

```python
print(
    df.group_by_dynamic(
        "time",
        every="1h",
        closed="both",
        group_by="groups",
        include_boundaries=True,
    ).agg(pl.col("n"))
)
```

```python
shape: (7, 5)
┌────────┬─────────────────────┬─────────────────────┬─────────────────────┬───────────┐
│ groups ┆ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ n         │
│ ---    ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---       │
│ str    ┆ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ list[i64] │
╞════════╪═════════════════════╪═════════════════════╪═════════════════════╪═══════════╡
│ a      ┆ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-15 23:00:00 ┆ [0]       │
│ a      ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ [0, 1, 2] │
│ a      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ [2]       │
│ a      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ [5, 6]    │
│ a      ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 04:00:00 ┆ 2021-12-16 03:00:00 ┆ [6]       │
│ b      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ [3, 4]    │
│ b      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ [4]       │
└────────┴─────────────────────┴─────────────────────┴─────────────────────┴───────────┘
```

```python
df = pl.DataFrame(
    {
        "idx": pl.int_range(0, 6, eager=True),
        "A": ["A", "A", "B", "B", "B", "C"],
    }
)
print(df)
```

```python
shape: (6, 2)
┌─────┬─────┐
│ idx ┆ A   │
│ --- ┆ --- │
│ i64 ┆ str │
╞═════╪═════╡
│ 0   ┆ A   │
│ 1   ┆ A   │
│ 2   ┆ B   │
│ 3   ┆ B   │
│ 4   ┆ B   │
│ 5   ┆ C   │
└─────┴─────┘
```

- period: 간격의 길이를 의미합니다. 없음인 경우 every와 같습니다. 만약, 정수 열을 그룹화하려는 경우 1i(1 인덱스 수) 으로 작성합니다.
  ex) 1i(길이 1), 10i(길이 10)
  ```python
  print((
      df.group_by_dynamic(
          "idx",
          every="2i",
          period="3i",
          include_boundaries=True,
          closed="right",
      ).agg(pl.col("A").alias("A_agg_list"))
  ))
  ```
  ```python
  shape: (4, 4)
  ┌─────────────────┬─────────────────┬─────┬─────────────────┐
  │ _lower_boundary ┆ _upper_boundary ┆ idx ┆ A_agg_list      │
  │ ---             ┆ ---             ┆ --- ┆ ---             │
  │ i64             ┆ i64             ┆ i64 ┆ list[str]       │
  ╞═════════════════╪═════════════════╪═════╪═════════════════╡
  │ -2              ┆ 1               ┆ -2  ┆ ["A", "A"]      │
  │ 0               ┆ 3               ┆ 0   ┆ ["A", "B", "B"] │
  │ 2               ┆ 5               ┆ 2   ┆ ["B", "B", "C"] │
  │ 4               ┆ 7               ┆ 4   ┆ ["C"]           │
  └─────────────────┴─────────────────┴─────┴─────────────────┘
  ```
    <aside>
    💡 dtype은 {Int32, Int64} 중 하나이어야 합니다. Int32는 일시적으로 Int64로 형변환되므로 성능이 중요한 경우 Int64 열을 사용시길 바랍니다.
    
    </aside>

두 코드는 동일하게 작동하지만, Pandas는 달리 Polars는 빈 창에 추가 행을 추가하지 않습니다. index_column의 간격을 균등하게 유지해야 하는 경우 DataFrame.upsample()과 결합하여 사용하시길 바랍니다.

```python
# polars
from datetime import datetime
import polars as pl

df = pl.DataFrame(
    {
        "time": pl.datetime_range(
            start=datetime(2021, 12, 16),
            end=datetime(2021, 12, 16, 3),
            interval="30m",
            eager=True,
        ),
        "n": range(7),
    }
)

print(df.group_by_dynamic("time", every="1h").agg(pl.col("n").sum()))
```

```python
shape: (4, 2)
┌─────────────────────┬─────┐
│ time                ┆ n   │
│ ---                 ┆ --- │
│ datetime[μs]        ┆ i64 │
╞═════════════════════╪═════╡
│ 2021-12-16 00:00:00 ┆ 1   │
│ 2021-12-16 01:00:00 ┆ 5   │
│ 2021-12-16 02:00:00 ┆ 9   │
│ 2021-12-16 03:00:00 ┆ 6   │
└─────────────────────┴─────┘
```

```python
# pandas
import pandas as pd
from datetime import datetime

df = pd.DataFrame(
    {
        "time": pl.datetime_range(
            start=datetime(2021, 12, 16),
            end=datetime(2021, 12, 16, 3),
            interval="30m",
            eager=True,
        ),
        "n": range(7),
    }
)

print(df.set_index("time").resample("h")["n"].sum().reset_index())
```

```
                 time  n
0 2021-12-16 00:00:00  1
1 2021-12-16 01:00:00  5
2 2021-12-16 02:00:00  9
3 2021-12-16 03:00:00  6
```

## **2.3 upsample**

업샘플링은 만약 친구와 한달에 한번 만나기로 해서 아래와 같이 계획을 짰는데 일주일에 한번 만나기로 했을 경우

| **날짜**   | **인원** |
| ---------- | -------- |
| 2021-06-01 | 3        |
| 2021-07-01 | 2        |
| …          | …        |
| 2021-12-01 | 5        |

— upsample →

| **날짜**   | **인원** |
| ---------- | -------- |
| 2021-06-01 | 3        |
| 2021-06-08 | null     |
| 2021-06-15 | null     |
| …          |          |
| 2021-11-30 | null     |

또는 2월과 5월에 만나자고 했는데 3, 4월에도 만나기로 계획을 변경했을 경우 데이터를 아래와 같이 추가할 때 사용하는 메서드입니다.

| **날짜**   | **인원** |
| ---------- | -------- |
| 2021-02-01 | 3        |
| 2021-05-01 | 2        |

— upsample →

| **날짜**   | **인원** |
| ---------- | -------- |
| 2021-02-01 | 3        |
| 2021-03-01 | null     |
| 2021-04-01 | null     |
| 2021-05-01 | 2        |

이처럼 특정 간격으로 데이터프레임을 업샘플링합니다. time_column을 기준으로 정렬되며, group_by 열을 전달하면 각 그룹 내에서만 정렬됩니다.

- 1ns(1나노초)
- 1us(1마이크로초)
- 1ms(1밀리초)
- 1s(1초)
- 1m(1분)
- 1h(1시간)

ex) 3d12h4m25s
(3일, 12시간 4분 25초)

- 1d(1역일)
- 1w(1역주)
- 1mo(1역월)
- 1q(1역분기)
- 1y(1역연도)
    <aside>
    💡 '역일'이란 다음 날의 해당 시간(서머타임으로 인해 24시간이 아닐 수 있음)을 의미합니다. '역주', '역월', '역분기', '역연도'도 마찬가지입니다.
    
    </aside>

```python
from datetime import datetime

df = pl.DataFrame(
    {
        "time": [
            datetime(2021, 6, 1),
            datetime(2021, 2, 1),
            datetime(2021, 4, 1),
            datetime(2021, 5, 1),
        ],
        "groups": ["A", "B", "A", "B"],
        "values": [0, 1, 2, 3],
    }
).set_sorted("time")

print(df)
```

```python
shape: (4, 3)
┌─────────────────────┬────────┬────────┐
│ time                ┆ groups ┆ values │
│ ---                 ┆ ---    ┆ ---    │
│ datetime[μs]        ┆ str    ┆ i64    │
╞═════════════════════╪════════╪════════╡
│ 2021-02-01 00:00:00 ┆ A      ┆ 0      │
│ 2021-04-01 00:00:00 ┆ B      ┆ 1      │
│ 2021-05-01 00:00:00 ┆ A      ┆ 2      │
│ 2021-06-01 00:00:00 ┆ B      ┆ 3      │
└─────────────────────┴────────┴────────┘
```

```python
# df.upsample(time_column="컬럼명", every="간격", group_by="그룹화 할 컬럼명", maintain_order=True)
print(df.upsample(
    time_column="time", every="1mo", group_by="groups", maintain_order=True
))
```

- time_column : 날짜 범위를 결정하는 데 사용됩니다. 해당 열을 정렬한 후 실행하셔야 합니다. 만약 정렬하지 않을 경우 해당 그룹에 대한 업샘플링을 출력하지 않습니다.
- every : 모든 기간을 간격에 맞게 쪼갭니다.
- group_by : 특정 열을 기준으로 먼저 그룹화한 다음 모든 그룹에 대해 업샘플링합니다.
- maintain_order : 기본값은 False 이며, True로 설정할 경우 원본 데이터프레임 순서를 유지합니다. 단, 이 과정은 속도가 느립니다.

```
shape: (7, 3)
┌─────────────────────┬────────┬────────┐
│ time                ┆ groups ┆ values │
│ ---                 ┆ ---    ┆ ---    │
│ datetime[μs]        ┆ str    ┆ i64    │
╞═════════════════════╪════════╪════════╡
│ 2021-02-01 00:00:00 ┆ A      ┆ 0      │
│ 2021-03-01 00:00:00 ┆ null   ┆ null   │
│ 2021-04-01 00:00:00 ┆ null   ┆ null   │
│ 2021-05-01 00:00:00 ┆ A      ┆ 2      │
│ 2021-04-01 00:00:00 ┆ B      ┆ 1      │
│ 2021-05-01 00:00:00 ┆ null   ┆ null   │
│ 2021-06-01 00:00:00 ┆ B      ┆ 3      │
└─────────────────────┴────────┴────────┘
```

```python
from datetime import datetime

df = pl.DataFrame(
    {
        "time": [
            datetime(2021, 6, 1),
            datetime(2021, 2, 1),
            datetime(2021, 4, 1),
            datetime(2021, 5, 1),
        ],
        "groups": ["A", "B", "A", "B"],
        "values": [0, 1, 2, 3],
    }
).set_sorted("time")

print(df)
```

```
shape: (4, 3)
┌─────────────────────┬────────┬────────┐
│ time                ┆ groups ┆ values │
│ ---                 ┆ ---    ┆ ---    │
│ datetime[μs]        ┆ str    ┆ i64    │
╞═════════════════════╪════════╪════════╡
│ 2021-06-01 00:00:00 ┆ A      ┆ 0      │
│ 2021-02-01 00:00:00 ┆ B      ┆ 1      │
│ 2021-04-01 00:00:00 ┆ A      ┆ 2      │
│ 2021-05-01 00:00:00 ┆ B      ┆ 3      │
└─────────────────────┴────────┴────────┘
```

```python
print(df.upsample(
    time_column="time", every="1mo", group_by="groups", maintain_order=True
))
```

```
shape: (4, 3)
┌─────────────────────┬────────┬────────┐
│ time                ┆ groups ┆ values │
│ ---                 ┆ ---    ┆ ---    │
│ datetime[μs]        ┆ str    ┆ i64    │
╞═════════════════════╪════════╪════════╡
│ 2021-02-01 00:00:00 ┆ B      ┆ 1      │
│ 2021-03-01 00:00:00 ┆ null   ┆ null   │
│ 2021-04-01 00:00:00 ┆ null   ┆ null   │
│ 2021-05-01 00:00:00 ┆ B      ┆ 3      │
└─────────────────────┴────────┴────────┘
```

## **2.4 rolling**

시간 또는 정수 열을 기준으로 롤링 그룹을 만듭니다. 일정한 간격의 경우 사용하는 group_by_dynamic과 달리 개별 값에 의해 결정됩니다.

시계열 <t_0, t_1, ..., t_n>이 있는 경우 기본적으로 생성되는 범위는 아래와 같습니다.

- (t_0 - period, t_0]
- (t_1 - period, t_1]
- …
- (t_n - period, t_n]

기본값이 아닌 offset을 전달하면 범위는 아래와 같습니다.

- (t_0 + offset, t_0 + offset + period]
- (t_1 + offset, t_1 + offset + period]
- …
- (t_n + offset, t_n + offset + period]

period 및 offset 인수는 timedelta에서 생성하거나 아래 문자열을 사용하여 생성합니다.

- 1ns(1나노초)
- 1us(1마이크로초)
- 1ms(1밀리초)
- 1s(1초)
- 1m(1분)
- 1h(1시간)

ex) 3d12h4m25s
(3일, 12시간 4분 25초)

- 1d(1역일)
- 1w(1역주)
- 1mo(1역월)
- 1q(1역분기)
- 1y(1역연도)
    <aside>
    💡 '역일'이란 다음 날의 해당 시간(서머타임으로 인해 24시간이 아닐 수 있음)을 의미합니다. '역주', '역월', '역분기', '역연도'도 마찬가지입니다.
    
    </aside>

```python
dates = [
    "2020-01-01 13:45:48",
    "2020-01-01 16:42:13",
    "2020-01-01 16:45:09",
    "2020-01-02 18:12:48",
    "2020-01-03 19:45:32",
    "2020-01-08 23:16:43",
]

df = pl.DataFrame({"dt": dates, "a": [3, 7, 5, 9, 2, 1]}).with_columns(
    pl.col("dt").str.strptime(pl.Datetime).set_sorted()
)

# df.rolling(index_column="컬럼명", period="길이").agg(집계관련코드)
out = df.rolling(index_column="dt", period="2d").agg(
    [
        pl.col("a"),
        pl.sum("a").alias("sum_a"),
        pl.min("a").alias("min_a"),
        pl.max("a").alias("max_a"),
    ]
)

assert out["sum_a"].to_list() == [3, 10, 15, 24, 11, 1]
assert out["max_a"].to_list() == [3, 7, 7, 9, 9, 1]
assert out["min_a"].to_list() == [3, 3, 3, 3, 2, 1]

print(out)
```

- index_column : 시간을 기준으로 그룹화하는 데 사용되는 열로 보통 날짜/날짜/시간 유형입니다. 이때, 그룹화할 열은 오름차순으로 정렬해야 합니다. 오름차순으로 정렬하지 않을 경우 에러가 납니다.
- period : 길이, 음수가 아닌 값

```
shape: (6, 5)
┌─────────────────────┬─────────────┬───────┬───────┬───────┐
│ dt                  ┆ a           ┆ sum_a ┆ min_a ┆ max_a │
│ ---                 ┆ ---         ┆ ---   ┆ ---   ┆ ---   │
│ datetime[μs]        ┆ list[i64]   ┆ i64   ┆ i64   ┆ i64   │
╞═════════════════════╪═════════════╪═══════╪═══════╪═══════╡
│ 2020-01-01 13:45:48 ┆ [3]         ┆ 3     ┆ 3     ┆ 3     │
│ 2020-01-01 16:42:13 ┆ [3, 7]      ┆ 10    ┆ 3     ┆ 7     │
│ 2020-01-01 16:45:09 ┆ [3, 7, 5]   ┆ 15    ┆ 3     ┆ 7     │
│ 2020-01-02 18:12:48 ┆ [3, 7, … 9] ┆ 24    ┆ 3     ┆ 9     │
│ 2020-01-03 19:45:32 ┆ [9, 2]      ┆ 11    ┆ 2     ┆ 9     │
│ 2020-01-08 23:16:43 ┆ [1]         ┆ 1     ┆ 1     ┆ 1     │
└─────────────────────┴─────────────┴───────┴───────┴───────┘
```

- offset : 지정된 기간을 이동시킵니다. -period(기본값)입니다. 아래 코드는 데이터를 1일씩 옮기면서 2일 기간 동안의 a 값을 묶은 것입니다.
  ```
  out = df.rolling(index_column="dt", period="2d", offset='1d').agg(pl.col("a"))
  print(out)
  ```
  ```
  shape: (6, 2)
  ┌─────────────────────┬───────────┐
  │ dt                  ┆ a         │
  │ ---                 ┆ ---       │
  │ datetime[μs]        ┆ list[i64] │
  ╞═════════════════════╪═══════════╡
  │ 2020-01-01 13:45:48 ┆ [9, 2]    │
  │ 2020-01-01 16:42:13 ┆ [9, 2]    │
  │ 2020-01-01 16:45:09 ┆ [9, 2]    │
  │ 2020-01-02 18:12:48 ┆ [2]       │
  │ 2020-01-03 19:45:32 ┆ []        │
  │ 2020-01-08 23:16:43 ┆ []        │
  └─────────────────────┴───────────┘
  ```
  | dt                  | period 범위                                | period 적용 값 | offset 범위                                | offset 적용 값 |
  | ------------------- | ------------------------------------------ | -------------- | ------------------------------------------ | -------------- |
  | 2020-01-01 13:45:48 | [2020-01-01 13:45:48, 2020-01-03 13:45:48] | [3,7,5,9]      | [2020-01-02 13:45:48, 2020-01-04 13:45:48] | [9,2]          |
  | 2020-01-01 16:42:13 | [2020-01-01 16:42:13, 2020-01-03 16:42:13] | [3,7,5,9]      | [2020-01-02 16:42:13, 2020-01-04 16:42:13] | [9,2]          |
  | 2020-01-01 16:45:09 | [2020-01-01 16:45:09, 2020-01-03 16:45:09] | [3,7,5,9]      | [2020-01-02 16:45:09, 2020-01-04 16:45:09] | [9,2]          |
  | 2020-01-02 18:12:48 | [2020-01-02 18:12:48, 2020-01-04 18:12:48] | [3,7,5,9]      | [2020-01-03 18:12:48, 2020-01-05 18:12:48] | [2]            |
  | 2020-01-03 19:45:32 | [2020-01-03 19:45:32, 2020-01-05 19:45:32] | [3,7,5,9]      | [2020-01-04 19:45:32, 2020-01-06 19:45:32] | []             |
  | 2020-01-08 23:16:43 | [2020-01-08 23:16:43, 2020-01-10 23:16:43] | [3,7,5,9]      | [2020-01-09 23:16:43, 2020-01-11 23:16:43] | []             |
- closed : 시간 간격의 어느 쪽을 닫을지 정의합니다.(포함관계)

  ```python
  dates = [
      "2020-01-01 00:00:00",
      "2020-01-01 16:42:13",
      "2020-01-01 16:45:09",
      "2020-01-02 18:12:48",
      "2020-01-03 00:00:00",
      "2020-01-08 23:16:43",
  ]

  df = pl.DataFrame({"dt": dates, "a": [3, 7, 5, 9, 2, 1]}).with_columns(
      pl.col("dt").str.strptime(pl.Datetime).set_sorted()
  )

  print(df)
  ```

  ```python
  shape: (6, 2)
  ┌─────────────────────┬─────┐
  │ dt                  ┆ a   │
  │ ---                 ┆ --- │
  │ datetime[μs]        ┆ i64 │
  ╞═════════════════════╪═════╡
  │ 2020-01-01 00:00:00 ┆ 3   │
  │ 2020-01-01 16:42:13 ┆ 7   │
  │ 2020-01-01 16:45:09 ┆ 5   │
  │ 2020-01-02 18:12:48 ┆ 9   │
  │ 2020-01-03 00:00:00 ┆ 2   │
  │ 2020-01-08 23:16:43 ┆ 1   │
  └─────────────────────┴─────┘
  ```

  - `closed="right"` : 시작 경계값 < dt ≤ 종료 경계값이 됩니다.
    ```python
    out = df.rolling(index_column="dt", period="2d", closed='right').agg(pl.col("a"))
    print(out)
    ```
    ```python
    shape: (6, 2)
    ┌─────────────────────┬─────────────┐
    │ dt                  ┆ a           │
    │ ---                 ┆ ---         │
    │ datetime[μs]        ┆ list[i64]   │
    ╞═════════════════════╪═════════════╡
    │ 2020-01-01 00:00:00 ┆ [3]         │
    │ 2020-01-01 16:42:13 ┆ [3, 7]      │
    │ 2020-01-01 16:45:09 ┆ [3, 7, 5]   │
    │ 2020-01-02 18:12:48 ┆ [3, 7, … 9] │
    │ 2020-01-03 00:00:00 ┆ [7, 5, … 2] │
    │ 2020-01-08 23:16:43 ┆ [1]         │
    └─────────────────────┴─────────────┘
    ```
  - `closed="left"`(기본값) : 시작 경계값 ≤ time < 종료 경계값이 됩니다.
    ```python
    out = df.rolling(index_column="dt", period="2d", closed='left').agg(pl.col("a"))
    print(out)
    ```
    ```python
    shape: (6, 2)
    ┌─────────────────────┬─────────────┐
    │ dt                  ┆ a           │
    │ ---                 ┆ ---         │
    │ datetime[μs]        ┆ list[i64]   │
    ╞═════════════════════╪═════════════╡
    │ 2020-01-01 00:00:00 ┆ []          │
    │ 2020-01-01 16:42:13 ┆ [3]         │
    │ 2020-01-01 16:45:09 ┆ [3, 7]      │
    │ 2020-01-02 18:12:48 ┆ [3, 7, 5]   │
    │ 2020-01-03 00:00:00 ┆ [3, 7, … 9] │
    │ 2020-01-08 23:16:43 ┆ []          │
    └─────────────────────┴─────────────┘
    ```
  - `closed="both"` : 시작 경계값 ≤ time ≤ 종료 경계값이 됩니다.
    ```python
    out = df.rolling(index_column="dt", period="2d", closed='both').agg(pl.col("a"))
    print(out)
    ```
    ```python
    shape: (6, 2)
    ┌─────────────────────┬─────────────┐
    │ dt                  ┆ a           │
    │ ---                 ┆ ---         │
    │ datetime[μs]        ┆ list[i64]   │
    ╞═════════════════════╪═════════════╡
    │ 2020-01-01 00:00:00 ┆ [3]         │
    │ 2020-01-01 16:42:13 ┆ [3, 7]      │
    │ 2020-01-01 16:45:09 ┆ [3, 7, 5]   │
    │ 2020-01-02 18:12:48 ┆ [3, 7, … 9] │
    │ 2020-01-03 00:00:00 ┆ [3, 7, … 2] │
    │ 2020-01-08 23:16:43 ┆ [1]         │
    └─────────────────────┴─────────────┘
    ```
  - `closed="none"` : 시작 경계값 < time < 종료 경계값이 됩니다.
    ```python
    out = df.rolling(index_column="dt", period="2d", closed='none').agg(pl.col("a"))
    print(out)
    ```
    ```python
    shape: (6, 2)
    ┌─────────────────────┬───────────┐
    │ dt                  ┆ a         │
    │ ---                 ┆ ---       │
    │ datetime[μs]        ┆ list[i64] │
    ╞═════════════════════╪═══════════╡
    │ 2020-01-01 00:00:00 ┆ []        │
    │ 2020-01-01 16:42:13 ┆ [3]       │
    │ 2020-01-01 16:45:09 ┆ [3, 7]    │
    │ 2020-01-02 18:12:48 ┆ [3, 7, 5] │
    │ 2020-01-03 00:00:00 ┆ [7, 5, 9] │
    │ 2020-01-08 23:16:43 ┆ []        │
    └─────────────────────┴───────────┘
    ```

다른 컬럼 그룹화와 결합할 수도 있습니다. group_by에 컬럼명을 입력하여 어떤 열을 기준으로 그룹별로 집계할지 정할 수 있습니다. group_by가 전달되면 출력 결과는 그룹화 할 컬럼을 기준으로 각 그룹 내에서 오름차순으로 정렬됩니다.

```python
df = df.with_columns(
    pl.Series("groups", ['a', 'b', 'a', 'b', 'a', 'b'])
)
df
```

```

```

```python
out = df.rolling(index_column="dt", period="2d", group_by="groups").agg(pl.col("a"))
print(out)
```

```
shape: (6, 3)
┌────────┬─────────────────────┬───────────┐
│ groups ┆ dt                  ┆ a         │
│ ---    ┆ ---                 ┆ ---       │
│ str    ┆ datetime[μs]        ┆ list[i64] │
╞════════╪═════════════════════╪═══════════╡
│ a      ┆ 2020-01-01 00:00:00 ┆ [3]       │
│ a      ┆ 2020-01-01 16:45:09 ┆ [3, 5]    │
│ a      ┆ 2020-01-03 00:00:00 ┆ [5, 2]    │
│ b      ┆ 2020-01-01 16:42:13 ┆ [7]       │
│ b      ┆ 2020-01-02 18:12:48 ┆ [7, 9]    │
│ b      ┆ 2020-01-08 23:16:43 ┆ [1]       │
└────────┴─────────────────────┴───────────┘
```

period 또는 offset에 인덱스 카운트를 사용하는 경우 index_column에 있는 값을 기준으로 합니다.

```python
df = pl.DataFrame({"int": [0, 4, 5, 6, 8], "value": [1, 4, 2, 4, 1]})
print(df.rolling("int", period="3i").agg(pl.col("int").alias("aggregated")))
```

```
shape: (5, 2)
┌─────┬────────────┐
│ int ┆ aggregated │
│ --- ┆ ---        │
│ i64 ┆ list[i64]  │
╞═════╪════════════╡
│ 0   ┆ [0]        │
│ 4   ┆ [4]        │
│ 5   ┆ [4, 5]     │
│ 6   ┆ [4, 5, 6]  │
│ 8   ┆ [6, 8]     │
└─────┴────────────┘
```

인덱스 수를 행 번호를 기준으로 하려면 rolling과 with_row_index()를 결합하는 것이 좋습니다.

인덱스에 대한 rolling의 경우 dtype은 {UInt32, UInt64, Int32, Int64} 중 하나이어야 합니다. 처음에 일시적으로 Int64로 형변환되므로 성능이 중요한 경우 Int64로 사용해주시길 바랍니다.

## **2.5 partition_by**

지정된 열을 기준으로 그룹화하고 여러 데이터프레임으로 분할하여 그룹별로 반환합니다.

```python
df = pl.DataFrame(
    {
        "a": ["a", "b", "a", "b", "c"],
        "b": [1, 2, 1, 3, 3],
        "c": [5, 4, 3, 2, 1],
    }
)

print(df.partition_by("a"))
```

- by : 그룹화할 열로 해당 열을 기준으로 파티션에 단일 열 이름을 전달합니다.
- maintain_order : 그룹의 순서가 입력 데이터와 일치하는지 확인합니다. 기본 분할 연산보다 느립니다.
- include_key : 출력 결과에 데이터프레임을 분할하는데 사용되는 열을 포함합니다.
- as_dict : 리스트 대신 딕셔너리를 반환합니다. 딕셔너리 키는 각 그룹을 식별하는 고유한 그룹 값의 튜플입니다.

```
[shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ a   ┆ 1   ┆ 3   │
└─────┴─────┴─────┘,
shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 2   ┆ 4   │
│ b   ┆ 3   ┆ 2   │
└─────┴─────┴─────┘,
shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘]
```

컬럼명을 리스트를 전달하거나 각 컬럼명을 순서대로 작성하여 여러 열을 기준으로 파티션을 분할합니다.

```
df.partition_by("a", "b")
```

```
[shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ a   ┆ 1   ┆ 3   │
└─────┴─────┴─────┘,
shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 2   ┆ 4   │
└─────┴─────┴─────┘,
shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 3   ┆ 2   │
└─────┴─────┴─────┘,
shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘]
```

`as_dict=True`를 지정하여 파티션을 딕셔너리로 반환합니다.

```
import polars.selectors as cs
df.partition_by(cs.string(), as_dict=True)
```

```
{('a',): shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ a   ┆ 1   ┆ 3   │
└─────┴─────┴─────┘,
('b',): shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 2   ┆ 4   │
│ b   ┆ 3   ┆ 2   │
└─────┴─────┴─────┘,
('c',): shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘}
```
