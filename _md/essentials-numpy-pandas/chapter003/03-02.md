---
chapter: NumPy :세 번째 걸음
title: NumPy를 이용한 선형대수학
date: 2024-07-10
---
# 행렬 연산 심화
![피그잼](/images/essentials-numpy-pandas/chapter01/행렬.png )

## 1.1 행렬 곱셈
행렬 곱셈은 두 행렬의 원소들을 특정 규칙에 따라 곱하고 더하는 연산입니다. 이 연산에서 결과 행렬의 크기는 첫 번째 행렬의 행 수와 두 번째 행렬의 열 수에 의해 결정됩니다. 곱셈이 가능하려면, 첫 번째 행렬의 열 수와 두 번째 행렬의 행 수가 일치해야 합니다. 예를 들어, (A)가 (m × n) 행렬이고 (B)가 (n × p) 행렬일 때, 이들의 곱 (C = AB)는 (m × p) 크기의 행렬이 됩니다.
행렬 곱셈의 중요한 특징 중 하나는 교환법칙이 일반적으로 성립하지 않는다는 점입니다. 즉, (AB ≠ BA)일 수 있습니다. 행렬 곱셈은 각 행과 열이 만나는 지점에서 특정 규칙을 적용하여 두 행렬의 정보를 결합해 새로운 정보를 생성하는 과정입니다. 예를 들어, 두 데이터 세트의 연관성을 분석하거나, 변환 매트릭스를 사용해 데이터나 이미지를 변환하는 데 사용됩니다.

![피그잼](/images/essentials-numpy-pandas/chapter01/행렬의곱.png )

```python-exec
import numpy as np

A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

C = np.dot(A, B)
print("행렬 A:")
print(A)
print("\n행렬 B:")
print(B)
print("\n행렬 곱셈 결과 (A * B):")
print(C)
```

## 1.2 역행렬
역행렬은 선형대수학에서 매우 중요한 개념입니다. 어떤 행렬 A가 있을 때, 이 행렬과 곱해서 단위행렬이 되는 행렬을 A의 역행렬이라고 합니다. 역행렬은 보통 A^(-1)로 표기하며, AA^(-1) = A^(-1)A = I와 같이 표현할 수 있습니다. 여기서 I는 단위행렬을 의미합니다.
역행렬은 모든 행렬에 대해 존재하지는 않습니다. 오직 정방행렬, 즉 행과 열의 수가 같은 행렬에 대해서만 역행렬이 존재할 수 있습니다. 그리고 그 중에서도 행렬식(determinant)이 0이 아닌 경우에만 역행렬을 구할 수 있습니다. 

![피그잼](/images/essentials-numpy-pandas/chapter01/역행렬.png )

```python-exec
A = np.array([[1, 2], [3, 4]])
print("A의 역행렬:")
print(A)
```
:::div{.callout}

**Tip !**

역행렬의 가장 중요한 특징은 원래 행렬의 효과를 정확히 취소한다는 점입니다. 예를 들어, 어떤 행렬 A가 벡터에 적용되어 변환을 일으켰다면, A의 역행렬 A^(-1)을 그 결과에 다시 적용하면 원래의 벡터로 돌아갑니다. 이는 마치 '실행 취소' 버튼을 누르는 것과 같은 효과를 냅니다.
:::

## 1.3 의사역행렬
![피그잼](/images/essentials-numpy-pandas/chapter01/의사역행렬.png )

의사역행렬은 일반적인 역행렬의 개념을 확장한 것입니다. 이는 모든 행렬에 대해 정의될 수 있어 정방행렬에 국한되지 않습니다. 일반적으로 A+로 표기되는 의사역행렬은 역행렬이 존재하지 않는 경우에도 계산할 수 있어 매우 유용합니다.
의사역행렬의 주요 용도 중 하나는 최소제곱법 문제 해결입니다. 이는 데이터 피팅이나 근사 해를 찾는 상황에서 특히 중요합니다. 완벽한 역행렬이 존재하지 않는 상황에서 의사역행렬은 '최선의 근사'를 제공합니다. 이는 마치 원래 변환을 가능한 한 가장 가깝게 되돌리는 역할을 합니다.

```python-exec
A = np.array([[1, 2, 3], [4, 5, 6]])
A_pinv = np.linalg.pinv(A)
print("행렬 A:")
print(A)
print("A의 의사역행렬:")
print( A_pinv)
```
# 2. 벡터 연산 심화

## 2.1 고유값 (Eigenvalues)

고유값은 선형대수학에서 매우 중요한 개념으로, 행렬 변환의 핵심적인 특성을 나타내는 스칼라 값입니다. 이 값은 행렬을 특정 스칼라 값으로 곱했을 때 방향이 변하지 않는 벡터, 즉 고유벡터에 대응합니다.
고유값과 고유벡터는 항상 쌍을 이루어 존재합니다. 예를 들어, λ가 고유값이고 v가 그에 대응하는 고유벡터라면, Av = λv라는 관계가 성립합니다. 여기서 A는 주어진 정방행렬입니다. 또한, 오직 정방행렬에 대해서만 계산할 수 있습니다. 그리고 n × n 정방행렬의 경우, 최대 n개의 고유값이 존재할 수 있습니다. 이는 행렬의 차원과 같은 수입니다.

```python-exec
A = np.array([[1, 2], [2, 3]])
eigenvalues = np.linalg.eigvals(A)

print("행렬 A:")
print(A)
print("고유값:", eigenvalues)
```
:::div{.callout}

**Tip !**

"예를 들어, -0.23606798이라는 고유값은 해당 방향으로 변환이 약 0.24배로 축소되고 방향이 반대가 됨을 나타내죠."
:::

## 2.2 고유벡터 (Eigenvectors)

![피그잼](/images/essentials-numpy-pandas/chapter01/고유벡터.png )

고유벡터는 행렬 변환에서 특별한 성질을 갖는 벡터입니다. 고유벡터는 행렬에 의해 변환될 때 그 방향이 변하지 않고 오직 크기만 변하는 0이 아닌 벡터를 말합니다. 각 고유값에는 대응하는 고유벡터가 존재합니다. 만약 λ가 행렬 A의 고유값이라면, Av = λv를 만족하는 0이 아닌 벡터 v가 바로 이 고유값에 대응하는 고유벡터입니다. 여기서 중요한 점은 서로 다른 고유값에 대응하는 고유벡터들은 선형독립이라는 것입니다. 이는 이 벡터들이 서로 독립적인 방향을 나타낸다는 의미입니다.

```python-exec
A = np.array([[1, 2], [2, 3]])
eigenvalues, eigenvectors = np.linalg.eig(A)

print("행렬 A:")
print(A)
print("고유벡터:", eigenvectors)
```

## 3. 선형 방정식

선형 방정식은 수학과 과학 분야에서 매우 중요한 개념입니다. Ax = b 형태로 표현되는 이 방정식에서 우리의 목표는 x를 찾는 것입니다. 여기서 A는 계수들로 이루어진 행렬, b는 상수들로 이루어진 벡터, 그리고 x는 우리가 구하고자 하는 미지수 벡터입니다.
이 방정식의 해는 세 가지 경우 중 하나에 해당합니다. 해가 전혀 존재하지 않을 수도 있고, 단 하나의 유일한 해가 있을 수도 있으며, 때로는 무한히 많은 해가 존재할 수도 있습니다. 이는 A 행렬의 특성과 b 벡터의 관계에 따라 결정됩니다.

![피그잼](/images/essentials-numpy-pandas/chapter01/선형방정식.png )

```python-exec
# 선형 방정식 Ax = b 설정
A = np.array([[3, 1], [1, 2]])
b = np.array([9, 8])

# 방정식 풀기
x = np.linalg.solve(A, b)

print("행렬 A:")
print(A)
print("벡터 b:", b)
print("해 x:", x)

# 해의 검증
print("검증 (Ax == b):", np.allclose(np.dot(A, x), b))
```


이번 장에서는 NumPy를 통해 선형대수학의 핵심 개념들을 살펴보았습니다. 행렬 연산, 역행렬, 의사역행렬, 고유값과 고유벡터, 선형 방정식 해결 등을 다루었습니다. 이 개념들은 데이터 변환, 시스템 분석, 최적화 등 실제 문제 해결에 광범위하게 적용됩니다.
NumPy는 이러한 복잡한 연산을 효율적으로 수행할 수 있게 해주는 강력한 도구입니다. 이를 통해 데이터 과학, 기계 학습, 신호 처리 등의 분야에서 선형대수학의 힘을 충분히 활용할 수 있습니다.